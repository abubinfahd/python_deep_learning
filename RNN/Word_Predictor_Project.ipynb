{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "faqs = \"\"\"\n",
        "In the bustling city of Meridian, there was a small café tucked away in a quiet corner. The café, known as The Morning Brew, was a favorite among the locals. Every morning, the aroma of freshly brewed coffee filled the air, drawing in early risers and night owls alike. The walls of the café were adorned with paintings from local artists, giving it a cozy and artistic vibe.\n",
        "\n",
        "One of the regulars, an old man named Harold, would always sit by the window with a newspaper in hand. He was a retired teacher and loved to watch the world go by as he sipped his coffee. Across the room, a young woman named Clara worked on her laptop, typing furiously as she worked on her novel. She found inspiration in the hum of the café, surrounded by people yet lost in her own world.\n",
        "\n",
        "One day, a stranger walked into The Morning Brew. He was a tall man with a kind face and an air of mystery. He ordered a black coffee and sat down at the corner table. His presence intrigued both Harold and Clara. Over the next few days, the stranger became a regular fixture at the café, always sitting in the same spot and quietly observing his surroundings.\n",
        "\n",
        "Harold, curious by nature, decided to strike up a conversation with the stranger. They talked about the weather, the city, and eventually, their lives. The stranger, whose name was Michael, shared that he was a traveler, always moving from one place to another. He had seen many cities and met many people, but he always felt a sense of loneliness.\n",
        "\n",
        "As days turned into weeks, Harold, Clara, and Michael formed an unlikely friendship. They shared stories, dreams, and fears, finding comfort in each other's company. The café became more than just a place for coffee; it became a sanctuary for them. They found solace in knowing that no matter where life took them, they had a place to return to.\n",
        "\n",
        "The Morning Brew, with its warm atmosphere and the bonds formed within its walls, became a symbol of connection and belonging. It was a reminder that even in a bustling city, one could find a sense of home in the most unexpected places.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "dM7GURKWWEhh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "EyvaRFnoWMIl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "OQsPQ0x9Wi51"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([faqs])"
      ],
      "metadata": {
        "id": "5qWwuThSWmTF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BG3xW-49Wvql",
        "outputId": "24cfc3d8-5374-4473-f379-3522255afceb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'a': 2,\n",
              " 'and': 3,\n",
              " 'in': 4,\n",
              " 'of': 5,\n",
              " 'was': 6,\n",
              " 'he': 7,\n",
              " 'café': 8,\n",
              " 'with': 9,\n",
              " 'to': 10,\n",
              " 'as': 11,\n",
              " 'morning': 12,\n",
              " 'coffee': 13,\n",
              " 'one': 14,\n",
              " 'harold': 15,\n",
              " 'always': 16,\n",
              " 'by': 17,\n",
              " 'stranger': 18,\n",
              " 'became': 19,\n",
              " 'they': 20,\n",
              " 'city': 21,\n",
              " 'brew': 22,\n",
              " 'it': 23,\n",
              " 'an': 24,\n",
              " 'his': 25,\n",
              " 'clara': 26,\n",
              " 'her': 27,\n",
              " 'that': 28,\n",
              " 'place': 29,\n",
              " 'bustling': 30,\n",
              " 'corner': 31,\n",
              " 'air': 32,\n",
              " 'walls': 33,\n",
              " 'from': 34,\n",
              " 'man': 35,\n",
              " 'named': 36,\n",
              " 'world': 37,\n",
              " 'worked': 38,\n",
              " 'on': 39,\n",
              " 'she': 40,\n",
              " 'found': 41,\n",
              " 'people': 42,\n",
              " 'into': 43,\n",
              " 'at': 44,\n",
              " 'days': 45,\n",
              " 'michael': 46,\n",
              " 'shared': 47,\n",
              " 'had': 48,\n",
              " 'many': 49,\n",
              " 'sense': 50,\n",
              " 'formed': 51,\n",
              " 'for': 52,\n",
              " 'them': 53,\n",
              " 'its': 54,\n",
              " 'meridian': 55,\n",
              " 'there': 56,\n",
              " 'small': 57,\n",
              " 'tucked': 58,\n",
              " 'away': 59,\n",
              " 'quiet': 60,\n",
              " 'known': 61,\n",
              " 'favorite': 62,\n",
              " 'among': 63,\n",
              " 'locals': 64,\n",
              " 'every': 65,\n",
              " 'aroma': 66,\n",
              " 'freshly': 67,\n",
              " 'brewed': 68,\n",
              " 'filled': 69,\n",
              " 'drawing': 70,\n",
              " 'early': 71,\n",
              " 'risers': 72,\n",
              " 'night': 73,\n",
              " 'owls': 74,\n",
              " 'alike': 75,\n",
              " 'were': 76,\n",
              " 'adorned': 77,\n",
              " 'paintings': 78,\n",
              " 'local': 79,\n",
              " 'artists': 80,\n",
              " 'giving': 81,\n",
              " 'cozy': 82,\n",
              " 'artistic': 83,\n",
              " 'vibe': 84,\n",
              " 'regulars': 85,\n",
              " 'old': 86,\n",
              " 'would': 87,\n",
              " 'sit': 88,\n",
              " 'window': 89,\n",
              " 'newspaper': 90,\n",
              " 'hand': 91,\n",
              " 'retired': 92,\n",
              " 'teacher': 93,\n",
              " 'loved': 94,\n",
              " 'watch': 95,\n",
              " 'go': 96,\n",
              " 'sipped': 97,\n",
              " 'across': 98,\n",
              " 'room': 99,\n",
              " 'young': 100,\n",
              " 'woman': 101,\n",
              " 'laptop': 102,\n",
              " 'typing': 103,\n",
              " 'furiously': 104,\n",
              " 'novel': 105,\n",
              " 'inspiration': 106,\n",
              " 'hum': 107,\n",
              " 'surrounded': 108,\n",
              " 'yet': 109,\n",
              " 'lost': 110,\n",
              " 'own': 111,\n",
              " 'day': 112,\n",
              " 'walked': 113,\n",
              " 'tall': 114,\n",
              " 'kind': 115,\n",
              " 'face': 116,\n",
              " 'mystery': 117,\n",
              " 'ordered': 118,\n",
              " 'black': 119,\n",
              " 'sat': 120,\n",
              " 'down': 121,\n",
              " 'table': 122,\n",
              " 'presence': 123,\n",
              " 'intrigued': 124,\n",
              " 'both': 125,\n",
              " 'over': 126,\n",
              " 'next': 127,\n",
              " 'few': 128,\n",
              " 'regular': 129,\n",
              " 'fixture': 130,\n",
              " 'sitting': 131,\n",
              " 'same': 132,\n",
              " 'spot': 133,\n",
              " 'quietly': 134,\n",
              " 'observing': 135,\n",
              " 'surroundings': 136,\n",
              " 'curious': 137,\n",
              " 'nature': 138,\n",
              " 'decided': 139,\n",
              " 'strike': 140,\n",
              " 'up': 141,\n",
              " 'conversation': 142,\n",
              " 'talked': 143,\n",
              " 'about': 144,\n",
              " 'weather': 145,\n",
              " 'eventually': 146,\n",
              " 'their': 147,\n",
              " 'lives': 148,\n",
              " 'whose': 149,\n",
              " 'name': 150,\n",
              " 'traveler': 151,\n",
              " 'moving': 152,\n",
              " 'another': 153,\n",
              " 'seen': 154,\n",
              " 'cities': 155,\n",
              " 'met': 156,\n",
              " 'but': 157,\n",
              " 'felt': 158,\n",
              " 'loneliness': 159,\n",
              " 'turned': 160,\n",
              " 'weeks': 161,\n",
              " 'unlikely': 162,\n",
              " 'friendship': 163,\n",
              " 'stories': 164,\n",
              " 'dreams': 165,\n",
              " 'fears': 166,\n",
              " 'finding': 167,\n",
              " 'comfort': 168,\n",
              " 'each': 169,\n",
              " \"other's\": 170,\n",
              " 'company': 171,\n",
              " 'more': 172,\n",
              " 'than': 173,\n",
              " 'just': 174,\n",
              " 'sanctuary': 175,\n",
              " 'solace': 176,\n",
              " 'knowing': 177,\n",
              " 'no': 178,\n",
              " 'matter': 179,\n",
              " 'where': 180,\n",
              " 'life': 181,\n",
              " 'took': 182,\n",
              " 'return': 183,\n",
              " 'warm': 184,\n",
              " 'atmosphere': 185,\n",
              " 'bonds': 186,\n",
              " 'within': 187,\n",
              " 'symbol': 188,\n",
              " 'connection': 189,\n",
              " 'belonging': 190,\n",
              " 'reminder': 191,\n",
              " 'even': 192,\n",
              " 'could': 193,\n",
              " 'find': 194,\n",
              " 'home': 195,\n",
              " 'most': 196,\n",
              " 'unexpected': 197,\n",
              " 'places': 198}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for sentence in faqs.split('.'):\n",
        "    #print(sentence)\n",
        "    #print(tokenizer.texts_to_sequences([sentence])[0])\n",
        "    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "    for i in range(1, len(tokenized_sentence)):\n",
        "        n_gram_sequence = tokenized_sentence[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "        #print(n_gram_sequence)"
      ],
      "metadata": {
        "id": "59dqCd6-Xbu6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Pxz53QaZeLR",
        "outputId": "276634ff-bd7d-4092-ffee-df477e91d803"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[4, 1],\n",
              " [4, 1, 30],\n",
              " [4, 1, 30, 21],\n",
              " [4, 1, 30, 21, 5],\n",
              " [4, 1, 30, 21, 5, 55],\n",
              " [4, 1, 30, 21, 5, 55, 56],\n",
              " [4, 1, 30, 21, 5, 55, 56, 6],\n",
              " [4, 1, 30, 21, 5, 55, 56, 6, 2],\n",
              " [4, 1, 30, 21, 5, 55, 56, 6, 2, 57],\n",
              " [4, 1, 30, 21, 5, 55, 56, 6, 2, 57, 8],\n",
              " [4, 1, 30, 21, 5, 55, 56, 6, 2, 57, 8, 58],\n",
              " [4, 1, 30, 21, 5, 55, 56, 6, 2, 57, 8, 58, 59],\n",
              " [4, 1, 30, 21, 5, 55, 56, 6, 2, 57, 8, 58, 59, 4],\n",
              " [4, 1, 30, 21, 5, 55, 56, 6, 2, 57, 8, 58, 59, 4, 2],\n",
              " [4, 1, 30, 21, 5, 55, 56, 6, 2, 57, 8, 58, 59, 4, 2, 60],\n",
              " [4, 1, 30, 21, 5, 55, 56, 6, 2, 57, 8, 58, 59, 4, 2, 60, 31],\n",
              " [1, 8],\n",
              " [1, 8, 61],\n",
              " [1, 8, 61, 11],\n",
              " [1, 8, 61, 11, 1],\n",
              " [1, 8, 61, 11, 1, 12],\n",
              " [1, 8, 61, 11, 1, 12, 22],\n",
              " [1, 8, 61, 11, 1, 12, 22, 6],\n",
              " [1, 8, 61, 11, 1, 12, 22, 6, 2],\n",
              " [1, 8, 61, 11, 1, 12, 22, 6, 2, 62],\n",
              " [1, 8, 61, 11, 1, 12, 22, 6, 2, 62, 63],\n",
              " [1, 8, 61, 11, 1, 12, 22, 6, 2, 62, 63, 1],\n",
              " [1, 8, 61, 11, 1, 12, 22, 6, 2, 62, 63, 1, 64],\n",
              " [65, 12],\n",
              " [65, 12, 1],\n",
              " [65, 12, 1, 66],\n",
              " [65, 12, 1, 66, 5],\n",
              " [65, 12, 1, 66, 5, 67],\n",
              " [65, 12, 1, 66, 5, 67, 68],\n",
              " [65, 12, 1, 66, 5, 67, 68, 13],\n",
              " [65, 12, 1, 66, 5, 67, 68, 13, 69],\n",
              " [65, 12, 1, 66, 5, 67, 68, 13, 69, 1],\n",
              " [65, 12, 1, 66, 5, 67, 68, 13, 69, 1, 32],\n",
              " [65, 12, 1, 66, 5, 67, 68, 13, 69, 1, 32, 70],\n",
              " [65, 12, 1, 66, 5, 67, 68, 13, 69, 1, 32, 70, 4],\n",
              " [65, 12, 1, 66, 5, 67, 68, 13, 69, 1, 32, 70, 4, 71],\n",
              " [65, 12, 1, 66, 5, 67, 68, 13, 69, 1, 32, 70, 4, 71, 72],\n",
              " [65, 12, 1, 66, 5, 67, 68, 13, 69, 1, 32, 70, 4, 71, 72, 3],\n",
              " [65, 12, 1, 66, 5, 67, 68, 13, 69, 1, 32, 70, 4, 71, 72, 3, 73],\n",
              " [65, 12, 1, 66, 5, 67, 68, 13, 69, 1, 32, 70, 4, 71, 72, 3, 73, 74],\n",
              " [65, 12, 1, 66, 5, 67, 68, 13, 69, 1, 32, 70, 4, 71, 72, 3, 73, 74, 75],\n",
              " [1, 33],\n",
              " [1, 33, 5],\n",
              " [1, 33, 5, 1],\n",
              " [1, 33, 5, 1, 8],\n",
              " [1, 33, 5, 1, 8, 76],\n",
              " [1, 33, 5, 1, 8, 76, 77],\n",
              " [1, 33, 5, 1, 8, 76, 77, 9],\n",
              " [1, 33, 5, 1, 8, 76, 77, 9, 78],\n",
              " [1, 33, 5, 1, 8, 76, 77, 9, 78, 34],\n",
              " [1, 33, 5, 1, 8, 76, 77, 9, 78, 34, 79],\n",
              " [1, 33, 5, 1, 8, 76, 77, 9, 78, 34, 79, 80],\n",
              " [1, 33, 5, 1, 8, 76, 77, 9, 78, 34, 79, 80, 81],\n",
              " [1, 33, 5, 1, 8, 76, 77, 9, 78, 34, 79, 80, 81, 23],\n",
              " [1, 33, 5, 1, 8, 76, 77, 9, 78, 34, 79, 80, 81, 23, 2],\n",
              " [1, 33, 5, 1, 8, 76, 77, 9, 78, 34, 79, 80, 81, 23, 2, 82],\n",
              " [1, 33, 5, 1, 8, 76, 77, 9, 78, 34, 79, 80, 81, 23, 2, 82, 3],\n",
              " [1, 33, 5, 1, 8, 76, 77, 9, 78, 34, 79, 80, 81, 23, 2, 82, 3, 83],\n",
              " [1, 33, 5, 1, 8, 76, 77, 9, 78, 34, 79, 80, 81, 23, 2, 82, 3, 83, 84],\n",
              " [14, 5],\n",
              " [14, 5, 1],\n",
              " [14, 5, 1, 85],\n",
              " [14, 5, 1, 85, 24],\n",
              " [14, 5, 1, 85, 24, 86],\n",
              " [14, 5, 1, 85, 24, 86, 35],\n",
              " [14, 5, 1, 85, 24, 86, 35, 36],\n",
              " [14, 5, 1, 85, 24, 86, 35, 36, 15],\n",
              " [14, 5, 1, 85, 24, 86, 35, 36, 15, 87],\n",
              " [14, 5, 1, 85, 24, 86, 35, 36, 15, 87, 16],\n",
              " [14, 5, 1, 85, 24, 86, 35, 36, 15, 87, 16, 88],\n",
              " [14, 5, 1, 85, 24, 86, 35, 36, 15, 87, 16, 88, 17],\n",
              " [14, 5, 1, 85, 24, 86, 35, 36, 15, 87, 16, 88, 17, 1],\n",
              " [14, 5, 1, 85, 24, 86, 35, 36, 15, 87, 16, 88, 17, 1, 89],\n",
              " [14, 5, 1, 85, 24, 86, 35, 36, 15, 87, 16, 88, 17, 1, 89, 9],\n",
              " [14, 5, 1, 85, 24, 86, 35, 36, 15, 87, 16, 88, 17, 1, 89, 9, 2],\n",
              " [14, 5, 1, 85, 24, 86, 35, 36, 15, 87, 16, 88, 17, 1, 89, 9, 2, 90],\n",
              " [14, 5, 1, 85, 24, 86, 35, 36, 15, 87, 16, 88, 17, 1, 89, 9, 2, 90, 4],\n",
              " [14, 5, 1, 85, 24, 86, 35, 36, 15, 87, 16, 88, 17, 1, 89, 9, 2, 90, 4, 91],\n",
              " [7, 6],\n",
              " [7, 6, 2],\n",
              " [7, 6, 2, 92],\n",
              " [7, 6, 2, 92, 93],\n",
              " [7, 6, 2, 92, 93, 3],\n",
              " [7, 6, 2, 92, 93, 3, 94],\n",
              " [7, 6, 2, 92, 93, 3, 94, 10],\n",
              " [7, 6, 2, 92, 93, 3, 94, 10, 95],\n",
              " [7, 6, 2, 92, 93, 3, 94, 10, 95, 1],\n",
              " [7, 6, 2, 92, 93, 3, 94, 10, 95, 1, 37],\n",
              " [7, 6, 2, 92, 93, 3, 94, 10, 95, 1, 37, 96],\n",
              " [7, 6, 2, 92, 93, 3, 94, 10, 95, 1, 37, 96, 17],\n",
              " [7, 6, 2, 92, 93, 3, 94, 10, 95, 1, 37, 96, 17, 11],\n",
              " [7, 6, 2, 92, 93, 3, 94, 10, 95, 1, 37, 96, 17, 11, 7],\n",
              " [7, 6, 2, 92, 93, 3, 94, 10, 95, 1, 37, 96, 17, 11, 7, 97],\n",
              " [7, 6, 2, 92, 93, 3, 94, 10, 95, 1, 37, 96, 17, 11, 7, 97, 25],\n",
              " [7, 6, 2, 92, 93, 3, 94, 10, 95, 1, 37, 96, 17, 11, 7, 97, 25, 13],\n",
              " [98, 1],\n",
              " [98, 1, 99],\n",
              " [98, 1, 99, 2],\n",
              " [98, 1, 99, 2, 100],\n",
              " [98, 1, 99, 2, 100, 101],\n",
              " [98, 1, 99, 2, 100, 101, 36],\n",
              " [98, 1, 99, 2, 100, 101, 36, 26],\n",
              " [98, 1, 99, 2, 100, 101, 36, 26, 38],\n",
              " [98, 1, 99, 2, 100, 101, 36, 26, 38, 39],\n",
              " [98, 1, 99, 2, 100, 101, 36, 26, 38, 39, 27],\n",
              " [98, 1, 99, 2, 100, 101, 36, 26, 38, 39, 27, 102],\n",
              " [98, 1, 99, 2, 100, 101, 36, 26, 38, 39, 27, 102, 103],\n",
              " [98, 1, 99, 2, 100, 101, 36, 26, 38, 39, 27, 102, 103, 104],\n",
              " [98, 1, 99, 2, 100, 101, 36, 26, 38, 39, 27, 102, 103, 104, 11],\n",
              " [98, 1, 99, 2, 100, 101, 36, 26, 38, 39, 27, 102, 103, 104, 11, 40],\n",
              " [98, 1, 99, 2, 100, 101, 36, 26, 38, 39, 27, 102, 103, 104, 11, 40, 38],\n",
              " [98, 1, 99, 2, 100, 101, 36, 26, 38, 39, 27, 102, 103, 104, 11, 40, 38, 39],\n",
              " [98,\n",
              "  1,\n",
              "  99,\n",
              "  2,\n",
              "  100,\n",
              "  101,\n",
              "  36,\n",
              "  26,\n",
              "  38,\n",
              "  39,\n",
              "  27,\n",
              "  102,\n",
              "  103,\n",
              "  104,\n",
              "  11,\n",
              "  40,\n",
              "  38,\n",
              "  39,\n",
              "  27],\n",
              " [98,\n",
              "  1,\n",
              "  99,\n",
              "  2,\n",
              "  100,\n",
              "  101,\n",
              "  36,\n",
              "  26,\n",
              "  38,\n",
              "  39,\n",
              "  27,\n",
              "  102,\n",
              "  103,\n",
              "  104,\n",
              "  11,\n",
              "  40,\n",
              "  38,\n",
              "  39,\n",
              "  27,\n",
              "  105],\n",
              " [40, 41],\n",
              " [40, 41, 106],\n",
              " [40, 41, 106, 4],\n",
              " [40, 41, 106, 4, 1],\n",
              " [40, 41, 106, 4, 1, 107],\n",
              " [40, 41, 106, 4, 1, 107, 5],\n",
              " [40, 41, 106, 4, 1, 107, 5, 1],\n",
              " [40, 41, 106, 4, 1, 107, 5, 1, 8],\n",
              " [40, 41, 106, 4, 1, 107, 5, 1, 8, 108],\n",
              " [40, 41, 106, 4, 1, 107, 5, 1, 8, 108, 17],\n",
              " [40, 41, 106, 4, 1, 107, 5, 1, 8, 108, 17, 42],\n",
              " [40, 41, 106, 4, 1, 107, 5, 1, 8, 108, 17, 42, 109],\n",
              " [40, 41, 106, 4, 1, 107, 5, 1, 8, 108, 17, 42, 109, 110],\n",
              " [40, 41, 106, 4, 1, 107, 5, 1, 8, 108, 17, 42, 109, 110, 4],\n",
              " [40, 41, 106, 4, 1, 107, 5, 1, 8, 108, 17, 42, 109, 110, 4, 27],\n",
              " [40, 41, 106, 4, 1, 107, 5, 1, 8, 108, 17, 42, 109, 110, 4, 27, 111],\n",
              " [40, 41, 106, 4, 1, 107, 5, 1, 8, 108, 17, 42, 109, 110, 4, 27, 111, 37],\n",
              " [14, 112],\n",
              " [14, 112, 2],\n",
              " [14, 112, 2, 18],\n",
              " [14, 112, 2, 18, 113],\n",
              " [14, 112, 2, 18, 113, 43],\n",
              " [14, 112, 2, 18, 113, 43, 1],\n",
              " [14, 112, 2, 18, 113, 43, 1, 12],\n",
              " [14, 112, 2, 18, 113, 43, 1, 12, 22],\n",
              " [7, 6],\n",
              " [7, 6, 2],\n",
              " [7, 6, 2, 114],\n",
              " [7, 6, 2, 114, 35],\n",
              " [7, 6, 2, 114, 35, 9],\n",
              " [7, 6, 2, 114, 35, 9, 2],\n",
              " [7, 6, 2, 114, 35, 9, 2, 115],\n",
              " [7, 6, 2, 114, 35, 9, 2, 115, 116],\n",
              " [7, 6, 2, 114, 35, 9, 2, 115, 116, 3],\n",
              " [7, 6, 2, 114, 35, 9, 2, 115, 116, 3, 24],\n",
              " [7, 6, 2, 114, 35, 9, 2, 115, 116, 3, 24, 32],\n",
              " [7, 6, 2, 114, 35, 9, 2, 115, 116, 3, 24, 32, 5],\n",
              " [7, 6, 2, 114, 35, 9, 2, 115, 116, 3, 24, 32, 5, 117],\n",
              " [7, 118],\n",
              " [7, 118, 2],\n",
              " [7, 118, 2, 119],\n",
              " [7, 118, 2, 119, 13],\n",
              " [7, 118, 2, 119, 13, 3],\n",
              " [7, 118, 2, 119, 13, 3, 120],\n",
              " [7, 118, 2, 119, 13, 3, 120, 121],\n",
              " [7, 118, 2, 119, 13, 3, 120, 121, 44],\n",
              " [7, 118, 2, 119, 13, 3, 120, 121, 44, 1],\n",
              " [7, 118, 2, 119, 13, 3, 120, 121, 44, 1, 31],\n",
              " [7, 118, 2, 119, 13, 3, 120, 121, 44, 1, 31, 122],\n",
              " [25, 123],\n",
              " [25, 123, 124],\n",
              " [25, 123, 124, 125],\n",
              " [25, 123, 124, 125, 15],\n",
              " [25, 123, 124, 125, 15, 3],\n",
              " [25, 123, 124, 125, 15, 3, 26],\n",
              " [126, 1],\n",
              " [126, 1, 127],\n",
              " [126, 1, 127, 128],\n",
              " [126, 1, 127, 128, 45],\n",
              " [126, 1, 127, 128, 45, 1],\n",
              " [126, 1, 127, 128, 45, 1, 18],\n",
              " [126, 1, 127, 128, 45, 1, 18, 19],\n",
              " [126, 1, 127, 128, 45, 1, 18, 19, 2],\n",
              " [126, 1, 127, 128, 45, 1, 18, 19, 2, 129],\n",
              " [126, 1, 127, 128, 45, 1, 18, 19, 2, 129, 130],\n",
              " [126, 1, 127, 128, 45, 1, 18, 19, 2, 129, 130, 44],\n",
              " [126, 1, 127, 128, 45, 1, 18, 19, 2, 129, 130, 44, 1],\n",
              " [126, 1, 127, 128, 45, 1, 18, 19, 2, 129, 130, 44, 1, 8],\n",
              " [126, 1, 127, 128, 45, 1, 18, 19, 2, 129, 130, 44, 1, 8, 16],\n",
              " [126, 1, 127, 128, 45, 1, 18, 19, 2, 129, 130, 44, 1, 8, 16, 131],\n",
              " [126, 1, 127, 128, 45, 1, 18, 19, 2, 129, 130, 44, 1, 8, 16, 131, 4],\n",
              " [126, 1, 127, 128, 45, 1, 18, 19, 2, 129, 130, 44, 1, 8, 16, 131, 4, 1],\n",
              " [126, 1, 127, 128, 45, 1, 18, 19, 2, 129, 130, 44, 1, 8, 16, 131, 4, 1, 132],\n",
              " [126,\n",
              "  1,\n",
              "  127,\n",
              "  128,\n",
              "  45,\n",
              "  1,\n",
              "  18,\n",
              "  19,\n",
              "  2,\n",
              "  129,\n",
              "  130,\n",
              "  44,\n",
              "  1,\n",
              "  8,\n",
              "  16,\n",
              "  131,\n",
              "  4,\n",
              "  1,\n",
              "  132,\n",
              "  133],\n",
              " [126,\n",
              "  1,\n",
              "  127,\n",
              "  128,\n",
              "  45,\n",
              "  1,\n",
              "  18,\n",
              "  19,\n",
              "  2,\n",
              "  129,\n",
              "  130,\n",
              "  44,\n",
              "  1,\n",
              "  8,\n",
              "  16,\n",
              "  131,\n",
              "  4,\n",
              "  1,\n",
              "  132,\n",
              "  133,\n",
              "  3],\n",
              " [126,\n",
              "  1,\n",
              "  127,\n",
              "  128,\n",
              "  45,\n",
              "  1,\n",
              "  18,\n",
              "  19,\n",
              "  2,\n",
              "  129,\n",
              "  130,\n",
              "  44,\n",
              "  1,\n",
              "  8,\n",
              "  16,\n",
              "  131,\n",
              "  4,\n",
              "  1,\n",
              "  132,\n",
              "  133,\n",
              "  3,\n",
              "  134],\n",
              " [126,\n",
              "  1,\n",
              "  127,\n",
              "  128,\n",
              "  45,\n",
              "  1,\n",
              "  18,\n",
              "  19,\n",
              "  2,\n",
              "  129,\n",
              "  130,\n",
              "  44,\n",
              "  1,\n",
              "  8,\n",
              "  16,\n",
              "  131,\n",
              "  4,\n",
              "  1,\n",
              "  132,\n",
              "  133,\n",
              "  3,\n",
              "  134,\n",
              "  135],\n",
              " [126,\n",
              "  1,\n",
              "  127,\n",
              "  128,\n",
              "  45,\n",
              "  1,\n",
              "  18,\n",
              "  19,\n",
              "  2,\n",
              "  129,\n",
              "  130,\n",
              "  44,\n",
              "  1,\n",
              "  8,\n",
              "  16,\n",
              "  131,\n",
              "  4,\n",
              "  1,\n",
              "  132,\n",
              "  133,\n",
              "  3,\n",
              "  134,\n",
              "  135,\n",
              "  25],\n",
              " [126,\n",
              "  1,\n",
              "  127,\n",
              "  128,\n",
              "  45,\n",
              "  1,\n",
              "  18,\n",
              "  19,\n",
              "  2,\n",
              "  129,\n",
              "  130,\n",
              "  44,\n",
              "  1,\n",
              "  8,\n",
              "  16,\n",
              "  131,\n",
              "  4,\n",
              "  1,\n",
              "  132,\n",
              "  133,\n",
              "  3,\n",
              "  134,\n",
              "  135,\n",
              "  25,\n",
              "  136],\n",
              " [15, 137],\n",
              " [15, 137, 17],\n",
              " [15, 137, 17, 138],\n",
              " [15, 137, 17, 138, 139],\n",
              " [15, 137, 17, 138, 139, 10],\n",
              " [15, 137, 17, 138, 139, 10, 140],\n",
              " [15, 137, 17, 138, 139, 10, 140, 141],\n",
              " [15, 137, 17, 138, 139, 10, 140, 141, 2],\n",
              " [15, 137, 17, 138, 139, 10, 140, 141, 2, 142],\n",
              " [15, 137, 17, 138, 139, 10, 140, 141, 2, 142, 9],\n",
              " [15, 137, 17, 138, 139, 10, 140, 141, 2, 142, 9, 1],\n",
              " [15, 137, 17, 138, 139, 10, 140, 141, 2, 142, 9, 1, 18],\n",
              " [20, 143],\n",
              " [20, 143, 144],\n",
              " [20, 143, 144, 1],\n",
              " [20, 143, 144, 1, 145],\n",
              " [20, 143, 144, 1, 145, 1],\n",
              " [20, 143, 144, 1, 145, 1, 21],\n",
              " [20, 143, 144, 1, 145, 1, 21, 3],\n",
              " [20, 143, 144, 1, 145, 1, 21, 3, 146],\n",
              " [20, 143, 144, 1, 145, 1, 21, 3, 146, 147],\n",
              " [20, 143, 144, 1, 145, 1, 21, 3, 146, 147, 148],\n",
              " [1, 18],\n",
              " [1, 18, 149],\n",
              " [1, 18, 149, 150],\n",
              " [1, 18, 149, 150, 6],\n",
              " [1, 18, 149, 150, 6, 46],\n",
              " [1, 18, 149, 150, 6, 46, 47],\n",
              " [1, 18, 149, 150, 6, 46, 47, 28],\n",
              " [1, 18, 149, 150, 6, 46, 47, 28, 7],\n",
              " [1, 18, 149, 150, 6, 46, 47, 28, 7, 6],\n",
              " [1, 18, 149, 150, 6, 46, 47, 28, 7, 6, 2],\n",
              " [1, 18, 149, 150, 6, 46, 47, 28, 7, 6, 2, 151],\n",
              " [1, 18, 149, 150, 6, 46, 47, 28, 7, 6, 2, 151, 16],\n",
              " [1, 18, 149, 150, 6, 46, 47, 28, 7, 6, 2, 151, 16, 152],\n",
              " [1, 18, 149, 150, 6, 46, 47, 28, 7, 6, 2, 151, 16, 152, 34],\n",
              " [1, 18, 149, 150, 6, 46, 47, 28, 7, 6, 2, 151, 16, 152, 34, 14],\n",
              " [1, 18, 149, 150, 6, 46, 47, 28, 7, 6, 2, 151, 16, 152, 34, 14, 29],\n",
              " [1, 18, 149, 150, 6, 46, 47, 28, 7, 6, 2, 151, 16, 152, 34, 14, 29, 10],\n",
              " [1, 18, 149, 150, 6, 46, 47, 28, 7, 6, 2, 151, 16, 152, 34, 14, 29, 10, 153],\n",
              " [7, 48],\n",
              " [7, 48, 154],\n",
              " [7, 48, 154, 49],\n",
              " [7, 48, 154, 49, 155],\n",
              " [7, 48, 154, 49, 155, 3],\n",
              " [7, 48, 154, 49, 155, 3, 156],\n",
              " [7, 48, 154, 49, 155, 3, 156, 49],\n",
              " [7, 48, 154, 49, 155, 3, 156, 49, 42],\n",
              " [7, 48, 154, 49, 155, 3, 156, 49, 42, 157],\n",
              " [7, 48, 154, 49, 155, 3, 156, 49, 42, 157, 7],\n",
              " [7, 48, 154, 49, 155, 3, 156, 49, 42, 157, 7, 16],\n",
              " [7, 48, 154, 49, 155, 3, 156, 49, 42, 157, 7, 16, 158],\n",
              " [7, 48, 154, 49, 155, 3, 156, 49, 42, 157, 7, 16, 158, 2],\n",
              " [7, 48, 154, 49, 155, 3, 156, 49, 42, 157, 7, 16, 158, 2, 50],\n",
              " [7, 48, 154, 49, 155, 3, 156, 49, 42, 157, 7, 16, 158, 2, 50, 5],\n",
              " [7, 48, 154, 49, 155, 3, 156, 49, 42, 157, 7, 16, 158, 2, 50, 5, 159],\n",
              " [11, 45],\n",
              " [11, 45, 160],\n",
              " [11, 45, 160, 43],\n",
              " [11, 45, 160, 43, 161],\n",
              " [11, 45, 160, 43, 161, 15],\n",
              " [11, 45, 160, 43, 161, 15, 26],\n",
              " [11, 45, 160, 43, 161, 15, 26, 3],\n",
              " [11, 45, 160, 43, 161, 15, 26, 3, 46],\n",
              " [11, 45, 160, 43, 161, 15, 26, 3, 46, 51],\n",
              " [11, 45, 160, 43, 161, 15, 26, 3, 46, 51, 24],\n",
              " [11, 45, 160, 43, 161, 15, 26, 3, 46, 51, 24, 162],\n",
              " [11, 45, 160, 43, 161, 15, 26, 3, 46, 51, 24, 162, 163],\n",
              " [20, 47],\n",
              " [20, 47, 164],\n",
              " [20, 47, 164, 165],\n",
              " [20, 47, 164, 165, 3],\n",
              " [20, 47, 164, 165, 3, 166],\n",
              " [20, 47, 164, 165, 3, 166, 167],\n",
              " [20, 47, 164, 165, 3, 166, 167, 168],\n",
              " [20, 47, 164, 165, 3, 166, 167, 168, 4],\n",
              " [20, 47, 164, 165, 3, 166, 167, 168, 4, 169],\n",
              " [20, 47, 164, 165, 3, 166, 167, 168, 4, 169, 170],\n",
              " [20, 47, 164, 165, 3, 166, 167, 168, 4, 169, 170, 171],\n",
              " [1, 8],\n",
              " [1, 8, 19],\n",
              " [1, 8, 19, 172],\n",
              " [1, 8, 19, 172, 173],\n",
              " [1, 8, 19, 172, 173, 174],\n",
              " [1, 8, 19, 172, 173, 174, 2],\n",
              " [1, 8, 19, 172, 173, 174, 2, 29],\n",
              " [1, 8, 19, 172, 173, 174, 2, 29, 52],\n",
              " [1, 8, 19, 172, 173, 174, 2, 29, 52, 13],\n",
              " [1, 8, 19, 172, 173, 174, 2, 29, 52, 13, 23],\n",
              " [1, 8, 19, 172, 173, 174, 2, 29, 52, 13, 23, 19],\n",
              " [1, 8, 19, 172, 173, 174, 2, 29, 52, 13, 23, 19, 2],\n",
              " [1, 8, 19, 172, 173, 174, 2, 29, 52, 13, 23, 19, 2, 175],\n",
              " [1, 8, 19, 172, 173, 174, 2, 29, 52, 13, 23, 19, 2, 175, 52],\n",
              " [1, 8, 19, 172, 173, 174, 2, 29, 52, 13, 23, 19, 2, 175, 52, 53],\n",
              " [20, 41],\n",
              " [20, 41, 176],\n",
              " [20, 41, 176, 4],\n",
              " [20, 41, 176, 4, 177],\n",
              " [20, 41, 176, 4, 177, 28],\n",
              " [20, 41, 176, 4, 177, 28, 178],\n",
              " [20, 41, 176, 4, 177, 28, 178, 179],\n",
              " [20, 41, 176, 4, 177, 28, 178, 179, 180],\n",
              " [20, 41, 176, 4, 177, 28, 178, 179, 180, 181],\n",
              " [20, 41, 176, 4, 177, 28, 178, 179, 180, 181, 182],\n",
              " [20, 41, 176, 4, 177, 28, 178, 179, 180, 181, 182, 53],\n",
              " [20, 41, 176, 4, 177, 28, 178, 179, 180, 181, 182, 53, 20],\n",
              " [20, 41, 176, 4, 177, 28, 178, 179, 180, 181, 182, 53, 20, 48],\n",
              " [20, 41, 176, 4, 177, 28, 178, 179, 180, 181, 182, 53, 20, 48, 2],\n",
              " [20, 41, 176, 4, 177, 28, 178, 179, 180, 181, 182, 53, 20, 48, 2, 29],\n",
              " [20, 41, 176, 4, 177, 28, 178, 179, 180, 181, 182, 53, 20, 48, 2, 29, 10],\n",
              " [20,\n",
              "  41,\n",
              "  176,\n",
              "  4,\n",
              "  177,\n",
              "  28,\n",
              "  178,\n",
              "  179,\n",
              "  180,\n",
              "  181,\n",
              "  182,\n",
              "  53,\n",
              "  20,\n",
              "  48,\n",
              "  2,\n",
              "  29,\n",
              "  10,\n",
              "  183],\n",
              " [20,\n",
              "  41,\n",
              "  176,\n",
              "  4,\n",
              "  177,\n",
              "  28,\n",
              "  178,\n",
              "  179,\n",
              "  180,\n",
              "  181,\n",
              "  182,\n",
              "  53,\n",
              "  20,\n",
              "  48,\n",
              "  2,\n",
              "  29,\n",
              "  10,\n",
              "  183,\n",
              "  10],\n",
              " [1, 12],\n",
              " [1, 12, 22],\n",
              " [1, 12, 22, 9],\n",
              " [1, 12, 22, 9, 54],\n",
              " [1, 12, 22, 9, 54, 184],\n",
              " [1, 12, 22, 9, 54, 184, 185],\n",
              " [1, 12, 22, 9, 54, 184, 185, 3],\n",
              " [1, 12, 22, 9, 54, 184, 185, 3, 1],\n",
              " [1, 12, 22, 9, 54, 184, 185, 3, 1, 186],\n",
              " [1, 12, 22, 9, 54, 184, 185, 3, 1, 186, 51],\n",
              " [1, 12, 22, 9, 54, 184, 185, 3, 1, 186, 51, 187],\n",
              " [1, 12, 22, 9, 54, 184, 185, 3, 1, 186, 51, 187, 54],\n",
              " [1, 12, 22, 9, 54, 184, 185, 3, 1, 186, 51, 187, 54, 33],\n",
              " [1, 12, 22, 9, 54, 184, 185, 3, 1, 186, 51, 187, 54, 33, 19],\n",
              " [1, 12, 22, 9, 54, 184, 185, 3, 1, 186, 51, 187, 54, 33, 19, 2],\n",
              " [1, 12, 22, 9, 54, 184, 185, 3, 1, 186, 51, 187, 54, 33, 19, 2, 188],\n",
              " [1, 12, 22, 9, 54, 184, 185, 3, 1, 186, 51, 187, 54, 33, 19, 2, 188, 5],\n",
              " [1, 12, 22, 9, 54, 184, 185, 3, 1, 186, 51, 187, 54, 33, 19, 2, 188, 5, 189],\n",
              " [1,\n",
              "  12,\n",
              "  22,\n",
              "  9,\n",
              "  54,\n",
              "  184,\n",
              "  185,\n",
              "  3,\n",
              "  1,\n",
              "  186,\n",
              "  51,\n",
              "  187,\n",
              "  54,\n",
              "  33,\n",
              "  19,\n",
              "  2,\n",
              "  188,\n",
              "  5,\n",
              "  189,\n",
              "  3],\n",
              " [1,\n",
              "  12,\n",
              "  22,\n",
              "  9,\n",
              "  54,\n",
              "  184,\n",
              "  185,\n",
              "  3,\n",
              "  1,\n",
              "  186,\n",
              "  51,\n",
              "  187,\n",
              "  54,\n",
              "  33,\n",
              "  19,\n",
              "  2,\n",
              "  188,\n",
              "  5,\n",
              "  189,\n",
              "  3,\n",
              "  190],\n",
              " [23, 6],\n",
              " [23, 6, 2],\n",
              " [23, 6, 2, 191],\n",
              " [23, 6, 2, 191, 28],\n",
              " [23, 6, 2, 191, 28, 192],\n",
              " [23, 6, 2, 191, 28, 192, 4],\n",
              " [23, 6, 2, 191, 28, 192, 4, 2],\n",
              " [23, 6, 2, 191, 28, 192, 4, 2, 30],\n",
              " [23, 6, 2, 191, 28, 192, 4, 2, 30, 21],\n",
              " [23, 6, 2, 191, 28, 192, 4, 2, 30, 21, 14],\n",
              " [23, 6, 2, 191, 28, 192, 4, 2, 30, 21, 14, 193],\n",
              " [23, 6, 2, 191, 28, 192, 4, 2, 30, 21, 14, 193, 194],\n",
              " [23, 6, 2, 191, 28, 192, 4, 2, 30, 21, 14, 193, 194, 2],\n",
              " [23, 6, 2, 191, 28, 192, 4, 2, 30, 21, 14, 193, 194, 2, 50],\n",
              " [23, 6, 2, 191, 28, 192, 4, 2, 30, 21, 14, 193, 194, 2, 50, 5],\n",
              " [23, 6, 2, 191, 28, 192, 4, 2, 30, 21, 14, 193, 194, 2, 50, 5, 195],\n",
              " [23, 6, 2, 191, 28, 192, 4, 2, 30, 21, 14, 193, 194, 2, 50, 5, 195, 4],\n",
              " [23, 6, 2, 191, 28, 192, 4, 2, 30, 21, 14, 193, 194, 2, 50, 5, 195, 4, 1],\n",
              " [23,\n",
              "  6,\n",
              "  2,\n",
              "  191,\n",
              "  28,\n",
              "  192,\n",
              "  4,\n",
              "  2,\n",
              "  30,\n",
              "  21,\n",
              "  14,\n",
              "  193,\n",
              "  194,\n",
              "  2,\n",
              "  50,\n",
              "  5,\n",
              "  195,\n",
              "  4,\n",
              "  1,\n",
              "  196],\n",
              " [23,\n",
              "  6,\n",
              "  2,\n",
              "  191,\n",
              "  28,\n",
              "  192,\n",
              "  4,\n",
              "  2,\n",
              "  30,\n",
              "  21,\n",
              "  14,\n",
              "  193,\n",
              "  194,\n",
              "  2,\n",
              "  50,\n",
              "  5,\n",
              "  195,\n",
              "  4,\n",
              "  1,\n",
              "  196,\n",
              "  197],\n",
              " [23,\n",
              "  6,\n",
              "  2,\n",
              "  191,\n",
              "  28,\n",
              "  192,\n",
              "  4,\n",
              "  2,\n",
              "  30,\n",
              "  21,\n",
              "  14,\n",
              "  193,\n",
              "  194,\n",
              "  2,\n",
              "  50,\n",
              "  5,\n",
              "  195,\n",
              "  4,\n",
              "  1,\n",
              "  196,\n",
              "  197,\n",
              "  198]]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = max([len(x) for x in input_sequences])"
      ],
      "metadata": {
        "id": "OcVb6nPaZyPK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO4c3zCVj5Ae",
        "outputId": "8606e503-6d2a-455f-931e-f4d92277b732"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "pad_sequences = pad_sequences(input_sequences, maxlen=max_length, padding='pre')\n",
        "pad_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecRCu6ZdaGIL",
        "outputId": "e26e96ac-a941-407b-c03d-b3ff19389035"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   4,   1],\n",
              "       [  0,   0,   0, ...,   4,   1,  30],\n",
              "       [  0,   0,   0, ...,   1,  30,  21],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   4,   1, 196],\n",
              "       [  0,   0,   0, ...,   1, 196, 197],\n",
              "       [  0,   0,   0, ..., 196, 197, 198]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Features\n",
        "X = pad_sequences[:, :-1]"
      ],
      "metadata": {
        "id": "yyd6OiYqac5e"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# target\n",
        "y = pad_sequences[:, -1]"
      ],
      "metadata": {
        "id": "4I2cPoSJau9u"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-XrTmF8b6wu",
        "outputId": "2d8a693c-0124-4ec0-bb18-5930ab2e7a6a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(351, 24)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Dz4mh79b84t",
        "outputId": "c308ca19-5d45-4148-a30b-87bf6de1d264"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(351,)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# on hot encoding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y, num_classes=len(tokenizer.word_index)+1)"
      ],
      "metadata": {
        "id": "y1UXUHTjb--l"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Hppa93-cYXd",
        "outputId": "3d1df0db-4809-4fca-8763-5f73845f3f76"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ],
      "metadata": {
        "id": "FtMsFs13jOE_"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=max_length-1))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(len(tokenizer.word_index)+1, activation='softmax'))"
      ],
      "metadata": {
        "id": "yZUaPSOWjbjE"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "DJSN56_NkN2O"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__FQw2hAkUN2",
        "outputId": "a88e01f4-cbee-4f12-cd19-a0515e8aca11"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 24, 100)           19900     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 150)               150600    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 199)               30049     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 200549 (783.39 KB)\n",
            "Trainable params: 200549 (783.39 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2t-c7mhFkhDW",
        "outputId": "7f8cfc4c-13a2-4240-a954-1542fed7782d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   0,   4],\n",
              "       [  0,   0,   0, ...,   0,   4,   1],\n",
              "       [  0,   0,   0, ...,   4,   1,  30],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 195,   4,   1],\n",
              "       [  0,   0,   0, ...,   4,   1, 196],\n",
              "       [  0,   0,   0, ...,   1, 196, 197]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1aY6ydjluiT",
        "outputId": "72c6cc74-ff94-4437-e8f5-aba56ec94d4e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "11/11 [==============================] - 3s 41ms/step - loss: 5.2847 - accuracy: 0.0541\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 5.1002 - accuracy: 0.0627\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 0s 40ms/step - loss: 4.9558 - accuracy: 0.0570\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 4.8921 - accuracy: 0.0855\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 0s 42ms/step - loss: 4.8597 - accuracy: 0.0627\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 0s 46ms/step - loss: 4.8361 - accuracy: 0.0997\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 4.8182 - accuracy: 0.0940\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 1s 49ms/step - loss: 4.7932 - accuracy: 0.0855\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 0s 41ms/step - loss: 4.7483 - accuracy: 0.0969\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 4.6896 - accuracy: 0.1083\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 4.6147 - accuracy: 0.1111\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 4.5293 - accuracy: 0.1140\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 1s 86ms/step - loss: 4.4121 - accuracy: 0.1111\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 1s 86ms/step - loss: 4.2832 - accuracy: 0.1339\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 1s 42ms/step - loss: 4.1419 - accuracy: 0.1368\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 0s 41ms/step - loss: 4.0007 - accuracy: 0.1453\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 0s 41ms/step - loss: 3.8327 - accuracy: 0.1709\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 3.6843 - accuracy: 0.1795\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 0s 42ms/step - loss: 3.5404 - accuracy: 0.2051\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 0s 42ms/step - loss: 3.3832 - accuracy: 0.2336\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 3.2378 - accuracy: 0.2450\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 0s 46ms/step - loss: 3.0755 - accuracy: 0.2621\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 2.9254 - accuracy: 0.2934\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 2.7845 - accuracy: 0.3305\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 2.6318 - accuracy: 0.3647\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 2.4875 - accuracy: 0.3789\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 2.3607 - accuracy: 0.4444\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 2.2434 - accuracy: 0.4701\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 2.1226 - accuracy: 0.5100\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 2.0231 - accuracy: 0.5413\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 1.9032 - accuracy: 0.5983\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 1.8084 - accuracy: 0.6439\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 1.6947 - accuracy: 0.6724\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 1.6021 - accuracy: 0.7151\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 1.5310 - accuracy: 0.7407\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 1s 85ms/step - loss: 1.4614 - accuracy: 0.7806\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 1s 82ms/step - loss: 1.3889 - accuracy: 0.7892\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 1s 85ms/step - loss: 1.3104 - accuracy: 0.8319\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 1.2377 - accuracy: 0.8490\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 1.1759 - accuracy: 0.8547\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 0s 41ms/step - loss: 1.1117 - accuracy: 0.8832\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 1.0489 - accuracy: 0.8832\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 0s 41ms/step - loss: 0.9938 - accuracy: 0.8917\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 0.9356 - accuracy: 0.9060\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 0s 40ms/step - loss: 0.8960 - accuracy: 0.9117\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.8522 - accuracy: 0.9174\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 0s 41ms/step - loss: 0.8105 - accuracy: 0.9288\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.7673 - accuracy: 0.9316\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 0s 42ms/step - loss: 0.7243 - accuracy: 0.9345\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 0s 42ms/step - loss: 0.6917 - accuracy: 0.9402\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 0s 42ms/step - loss: 0.6587 - accuracy: 0.9516\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 0s 42ms/step - loss: 0.6336 - accuracy: 0.9544\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 0.6027 - accuracy: 0.9573\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.5756 - accuracy: 0.9573\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.5529 - accuracy: 0.9630\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 0s 41ms/step - loss: 0.5322 - accuracy: 0.9630\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 0.5079 - accuracy: 0.9601\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 0s 42ms/step - loss: 0.4912 - accuracy: 0.9601\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.4783 - accuracy: 0.9630\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 1s 77ms/step - loss: 0.4638 - accuracy: 0.9573\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 1s 83ms/step - loss: 0.4366 - accuracy: 0.9658\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 1s 86ms/step - loss: 0.4165 - accuracy: 0.9630\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 1s 86ms/step - loss: 0.4057 - accuracy: 0.9601\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.4031 - accuracy: 0.9630\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 0s 42ms/step - loss: 0.3763 - accuracy: 0.9658\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 0.3527 - accuracy: 0.9658\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 0s 42ms/step - loss: 0.3409 - accuracy: 0.9658\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 0s 42ms/step - loss: 0.3285 - accuracy: 0.9658\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 0.3163 - accuracy: 0.9687\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 0.3074 - accuracy: 0.9687\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.2949 - accuracy: 0.9715\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 0.2860 - accuracy: 0.9687\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 0s 42ms/step - loss: 0.2760 - accuracy: 0.9687\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 0.2686 - accuracy: 0.9715\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.2590 - accuracy: 0.9715\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 0.2552 - accuracy: 0.9715\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.2470 - accuracy: 0.9658\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.2391 - accuracy: 0.9715\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.2329 - accuracy: 0.9658\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 0.2268 - accuracy: 0.9687\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 0.2206 - accuracy: 0.9687\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 0.2162 - accuracy: 0.9658\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 0s 39ms/step - loss: 0.2099 - accuracy: 0.9658\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 1s 70ms/step - loss: 0.2058 - accuracy: 0.9687\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 1s 85ms/step - loss: 0.2021 - accuracy: 0.9630\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 0.1977 - accuracy: 0.9715\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 0.1926 - accuracy: 0.9687\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.1862 - accuracy: 0.9715\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 0.1826 - accuracy: 0.9658\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 0s 42ms/step - loss: 0.1789 - accuracy: 0.9658\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.1767 - accuracy: 0.9658\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 0.1711 - accuracy: 0.9715\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.1682 - accuracy: 0.9687\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.1655 - accuracy: 0.9687\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 0.1647 - accuracy: 0.9687\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 0s 42ms/step - loss: 0.1588 - accuracy: 0.9715\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 0.1575 - accuracy: 0.9601\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 0.1544 - accuracy: 0.9658\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.1514 - accuracy: 0.9687\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 0s 41ms/step - loss: 0.1483 - accuracy: 0.9687\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b2297fd6ce0>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# define the text and tokenizer\n",
        "text = \"there\"\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "  # tokenize\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "\n",
        "  # pad\n",
        "  pad_text = pad_sequences([token_text], maxlen=max_length-1, padding='pre')\n",
        "\n",
        "  # prediction = model.predict(pad_text).shape\n",
        "  # prediction\n",
        "  pos = np.argmax(model.predict(pad_text))\n",
        "\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "      if index == pos:\n",
        "          text += ' ' + word\n",
        "          print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJTULvXcmQWv",
        "outputId": "f8038ab3-50a2-4039-b4d0-4ef5f2586e11"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "there was\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "there was a\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "there was a reminder\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "there was a reminder that\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "there was a reminder that even\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the text and tokenizer\n",
        "text = \"I love\"\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "  # tokenize\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "\n",
        "  # pad\n",
        "  pad_text = pad_sequences([token_text], maxlen=max_length-1, padding='pre')\n",
        "\n",
        "  # prediction = model.predict(pad_text).shape\n",
        "  # prediction\n",
        "  pos = np.argmax(model.predict(pad_text))\n",
        "\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "      if index == pos:\n",
        "          text += ' ' + word\n",
        "          print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWqapeorrT18",
        "outputId": "3d820289-ce12-417d-e38e-c9aa62d05347"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "I love found\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "I love found inspiration\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "I love found inspiration in\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "I love found inspiration in the\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "I love found inspiration in the hum\n"
          ]
        }
      ]
    }
  ]
}